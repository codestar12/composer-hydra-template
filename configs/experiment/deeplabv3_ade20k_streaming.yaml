# @package _global_
defaults:
 - override /trainer: default.yaml
 - override /model: null
 - override /dataset: null
 - override /scheduler: null
 - override /optimizer: null
 - override /logger: null
 - override /algorithms: null

seed: 42

name: test-ade20k

logger:
  wandb: 
    _target_: composer.loggers.wandb_logger.WandBLogger
    name: ${name}
    project: hydra-test
  
trainer:
  max_duration: 128ep
  grad_accum: auto
  dist_timeout: 60

model:
  _target_: composer.models.composer_deeplabv3
  initializers:
    - kaiming_normal
    - bn_ones
  num_classes: 150
  backbone_arch: resnet101
  backbone_weights: IMAGENET1K_V2
  use_plus: true
  sync_bn: false

scheduler:
  _target_: composer.optim.scheduler.CosineAnnealingScheduler
  t_max: 1dur

optimizer:
  _target_: composer.optim.DecoupledSGDW
  lr: 0.08
  momentum: 0.9
  weight_decay: 5.0e-5
  dampening: 0
  nesterov: false

dataset:
  train_batch_size: 128
  eval_batch_size: 128

  train_dataset:
    _target_: src.dataset.ade20k.ade20k.build_streaming_ade20k_dataloader
    remote: s3://mosaicml-internal-dataset-ade20k/mds/2/
    split: train
    pin_memory: true
    timeout: 0
    prefetch_factor: 2
    persistent_workers: true
    num_workers: 8

  eval_dataset:
    _target_: src.dataset.ade20k.ade20k.build_streaming_ade20k_dataloader
    remote: s3://mosaicml-internal-dataset-ade20k/mds/2/
    split: val
    shuffle: false
    pin_memory: true
    timeout: 0
    prefetch_factor: 2
    persistent_workers: true
    num_workers: 8